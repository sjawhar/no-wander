name: lstm-1l-64-normalize
projectId: prmqc6jjx
machineType: GPU+
container: sjawhar/no-wander:train
containerUser: tf
workingDirectory: /home/tf
command: |
  python3 -m no_wander train \
    --layers '[
      {"type": "LSTM", "units": 64, "ic_params": {"dropout": 0.2, "batchnorm": true}},
      {"type": "Dense", "units": 32, "activation": "relu", "ic_params": {"dropout": 0.2, "batchnorm": true}}
    ]' \
    --sample-size 128 \
    --sequence-size 6 \
    --preprocess normalize \
    --epochs 1000 \
    --gradient-metrics \
    /storage/no-wander/data/1572178629-1584963221-train.h5 \
    /artifacts
modelType: Tensorflow
modelPath: /artifacts/model_best
